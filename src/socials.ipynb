{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Topológica de Dados Biológicos\n",
    "Análise utilizando dados da dengue, turismo domestico e internacional, PIB e Renda Mensal.\n",
    "\n",
    "### To-Do:\n",
    "    - [] Decidir a utilizacao de alguma funcao de projecao\n",
    "\n",
    "    - [] Escolher o percentual de overlap e a quantidade de hypercubos\n",
    "\n",
    "    - [] Analisar os mappers gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import OrderedDict, Union\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kmapper as km\n",
    "import os\n",
    "import unidecode\n",
    "\n",
    "YEARS = ['2010', '2011', '2012', '2013', '2014', '2015']\n",
    "\n",
    "# Os paths levam em consideracao a organizacao deste repositorio.\n",
    "\n",
    "pathSlash = '/'\n",
    "if (platform.system() == 'Windows'):\n",
    "    pathSlash = \"\\\\\"\n",
    "\n",
    "\n",
    "workingDirectory  = os.path.abspath( os.getcwd() )\n",
    "\n",
    "citiesPath = workingDirectory + f'{pathSlash}data{pathSlash}Cities-Data.csv'\n",
    "socialPath = workingDirectory + f'{pathSlash}data{pathSlash}moreInfo.csv' \n",
    "denguePath = [workingDirectory + f'{pathSlash}data{pathSlash}strict-data{pathSlash}{year}DengueData.csv' for year in YEARS] \n",
    "\n",
    "domesticoOutputPaths = [workingDirectory + f'{pathSlash}mappers{pathSlash}strict-data{pathSlash}{year}{pathSlash}{year}DengueComTurismoDomestico.html' for year in YEARS]\n",
    "internacionalOutputPaths = [workingDirectory + f'{pathSlash}mappers{pathSlash}strict-data{pathSlash}{year}{pathSlash}{year}DengueComTurismoInternacional.html' for year in YEARS]\n",
    "ambosOutputPaths = [workingDirectory + f'{pathSlash}mappers{pathSlash}strict-data{pathSlash}{year}{pathSlash}{year}DengueComTurismoDomestico-Internacional.html' for year in YEARS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per100k(n: int, citypop: float) -> float:\n",
    "    '''\n",
    "        Calcula a quantidade de casos por 100 mil pessoas de um certo municipio\n",
    "    '''\n",
    "    return((n/citypop)*100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndCreateData() -> OrderedDict:\n",
    "    '''\n",
    "        Realiza a leitura dos csv e organiza-os em um unico dict onde cada cidade possui seus dados\n",
    "        Exemplo do dict final:\n",
    "        ```\n",
    "            mergedData = {\n",
    "                'municipioDoRJ1': {\n",
    "                    '2010': {\n",
    "                        'PIB': 15000,                   # PIB deste municipio\n",
    "                        'Populacao': 10000,             # Populacao deste municipio\n",
    "                        'TurismoDomestico': 1203,       # Quantidade de turistas brasileiros que visitaram a municipio\n",
    "                        'TurismoInternacional': 3111,   # Quantidade de turistas estrangeiros que visitaram o municipio\n",
    "                        'Casos': [2,3,1,2,3,...]        # Quantidade de casos por semana. Tamanho da lista: 52 (semanas)\n",
    "                    },\n",
    "                    '2011': {\n",
    "                        'PIB': ...\n",
    "                    }\n",
    "                },\n",
    "                'municipioDoRJ2': {\n",
    "                    ...\n",
    "                }\n",
    "            }\n",
    "\n",
    "        ```\n",
    "\n",
    "    '''\n",
    "    mergedData = OrderedDict()\n",
    "\n",
    "    citiesData = pd.read_csv(citiesPath) \n",
    "    socialData = pd.read_csv(socialPath)\n",
    "    socialData.rename( columns={'Unnamed: 0': 'City'}, inplace=True )\n",
    "    dengueData = [ pd.read_csv(year).drop(['Lat', 'Lng'], axis=1) for year in denguePath ]\n",
    "    \n",
    "    # Padronizar os nomes das cidades do rio\n",
    "    citiesData['City'] = citiesData['City'].apply(lambda x: unidecode.unidecode(x.lower()))   \n",
    "    socialData['City'] = socialData['City'].apply(lambda x: unidecode.unidecode(x.lower()))   \n",
    "    for index, _ in enumerate(YEARS):\n",
    "        dengueData[index]['City'] = dengueData[index]['City'].apply(lambda x: unidecode.unidecode(x.lower()))   \n",
    "\n",
    "    # Substituir os valores nulos como zeros\n",
    "    socialData['Domésticos'] = socialData['Domésticos'].fillna(0)\n",
    "    socialData['Internacionais'] = socialData['Internacionais'].fillna(0)\n",
    "    \n",
    "\n",
    "    # Popular o dict final com os subdicts\n",
    "    citiesNameList = citiesData['City']\n",
    "    for city in citiesNameList:\n",
    "        mergedData[city] = OrderedDict()\n",
    "        for year in YEARS:\n",
    "            mergedData[city][year] = OrderedDict()\n",
    "\n",
    "\n",
    "    # Preencher para cada cidade os dados de um certo ano\n",
    "    citiesIndexed = citiesData.set_index('City')\n",
    "    socialIndexed = socialData.set_index('City')\n",
    "\n",
    "    # Itera pelos anos\n",
    "    for index, yearData in enumerate(dengueData):\n",
    "        yearIndexed = yearData.set_index('City')\n",
    "\n",
    "        # Itera por todas as cidades daquele ano e adiciona os valores\n",
    "        for city in citiesNameList:\n",
    "            mergedData[city][YEARS[index]]['PIB'] = citiesIndexed.loc[city]['PIB']\n",
    "            mergedData[city][YEARS[index]]['Populacao'] = citiesIndexed.loc[city]['Population']\n",
    "            mergedData[city][YEARS[index]]['TurismoDomestico'] = socialIndexed.loc[city]['Domésticos']\n",
    "            mergedData[city][YEARS[index]]['TurismoInternacional'] = socialIndexed.loc[city]['Internacionais']\n",
    "            mergedData[city][YEARS[index]]['Casos'] = list(yearIndexed.loc[city][1:53])\n",
    "        \n",
    "    return mergedData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVectors(data: OrderedDict, year: str, analysisType: int) -> Union[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "        Cria a nuvem de pontos, utilizando uma lista de vetores, e a lista de labels.\n",
    "        Cada vetor pode possuir de 4 a 5 features, dependendo do tipo de analise feita.\n",
    "\n",
    "        p = (x,y,z,w) = (PIB, Turismo, Casos Ate a semana x, semana x)\n",
    "\n",
    "        O tipo de analise pode variar sendo:\n",
    "            1: Turismo domestico\n",
    "            2: Turismo Internacional\n",
    "            3: Ambos\n",
    "    '''\n",
    "    VectorList = []\n",
    "    LabelList = []\n",
    "\n",
    "    cities = list(data.keys())\n",
    "    # Cria os vetores iterando por todas as cidades\n",
    "    for city in cities:\n",
    "\n",
    "        # Pega o ano a ser analisado\n",
    "        thisCityDict = data[city][year]\n",
    "        thisCityPopulation = thisCityDict['Populacao']\n",
    "\n",
    "        # Variavel para a acumulacao dos casos de dengue ate a semana x\n",
    "        cummulative = 0\n",
    "        for i in range(0,52):\n",
    "            Vector = []\n",
    "            \n",
    "            # PIB\n",
    "            Vector.append( thisCityDict['PIB'] )\n",
    "\n",
    "            # Turismo Domestico\n",
    "            if(analysisType == 1 or analysisType == 3):\n",
    "                Vector.append( thisCityDict['TurismoDomestico'] )\n",
    "\n",
    "            # Turismo Internacional\n",
    "            if(analysisType == 2 or analysisType == 3):\n",
    "                Vector.append( thisCityDict['TurismoInternacional'] )\n",
    "\n",
    "            # Casos acumulados\n",
    "            cummulative += per100k( int(thisCityDict['Casos'][i]), thisCityPopulation )\n",
    "            Vector.append( cummulative )\n",
    "\n",
    "            # Semana\n",
    "            Vector.append(i+1)\n",
    "\n",
    "            # Adicionar ao PointCloud\n",
    "            VectorList.append(Vector)\n",
    "\n",
    "            # Adicionar a lista de labels\n",
    "\n",
    "            # Se usou domestico\n",
    "            if(analysisType == 1):\n",
    "                label = f\"{city}, Casos/100k: {cummulative}, Semana: {i}, TDomestico: {thisCityDict['TurismoDomestico']}, PIB: {thisCityDict['PIB']}\"\n",
    "\n",
    "            # Se usou internacional\n",
    "            if(analysisType == 2):\n",
    "                label = f\"{city}, Casos/100k: {cummulative}, Semana: {i}, TInternacional: {thisCityDict['TurismoInternacional']}, PIB: {thisCityDict['PIB']}\"\n",
    "\n",
    "            # Se usou os dois\n",
    "            if(analysisType == 3):\n",
    "                label = f\"{city}, Casos/100k: {cummulative}, Semana: {i}, TDomestico: {thisCityDict['TurismoDomestico']}, TInternacional: {thisCityDict['TurismoInternacional']}, PIB: {thisCityDict['PIB']}\"\n",
    "\n",
    "\n",
    "            LabelList.append(label)\n",
    "\n",
    "\n",
    "    return np.array(VectorList), np.array(LabelList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputPathFromAnalisysType(year: str, analysisType: int):\n",
    "    '''\n",
    "        Gera o path para o output do algoritmo mapper.\n",
    "        Leva em consideracao o ano de analise e o tipo de analise definidos na funcao main().\n",
    "    '''\n",
    "    \n",
    "    # Define o tipo de analise\n",
    "    variableToUse = None\n",
    "    if(analysisType == 1):\n",
    "        variableToUse = domesticoOutputPaths\n",
    "    elif(analysisType == 2):\n",
    "        variableToUse = internacionalOutputPaths\n",
    "    elif(analysisType == 3):\n",
    "        variableToUse = ambosOutputPaths\n",
    "    \n",
    "    mapperTitle = str()\n",
    "    outputPath = str()\n",
    "\n",
    "    # Parser para conferir o ano e o titulo do mapper\n",
    "    for path in variableToUse:\n",
    "        splittedPath = path.split('/')\n",
    "        #Check year\n",
    "        if(year == splittedPath[len(splittedPath)-2]):\n",
    "            mapperTitle = splittedPath[-1].split('.')[0]\n",
    "            outputPath = path\n",
    "        \n",
    "    return outputPath, mapperTitle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMapper(NPC: np.ndarray, Labels: np.ndarray, year: str, analysisType: int, perc_overlap: float, n_cubes: int):\n",
    "    '''\n",
    "        Aplica o algoritmo mapper e salva a visualizacao.\n",
    "    '''\n",
    "    outPath, title = getOutputPathFromAnalisysType(year, analysisType)\n",
    "\n",
    "    mapper = km.KeplerMapper(verbose=1)\n",
    "\n",
    "\n",
    "    # Definicao da funcao de projecao\n",
    "\n",
    "    # lens = mapper.project(\n",
    "    #     NormalizedVectorList, \n",
    "    #     projection=[4],\n",
    "    #     # scaler=StandardScaler()\n",
    "    # )\n",
    "\n",
    "    # Criar um complexo simplicial\n",
    "    # Utilizar 'lens' ao inves de 'NPC' caso seja utilizado o mapper.project acima\n",
    "    graph = mapper.map(NPC,\n",
    "                        cover=km.Cover(n_cubes=n_cubes, perc_overlap=perc_overlap),\n",
    "                        clusterer= DBSCAN()\n",
    "                        )\n",
    "\n",
    "    # Criacao da visualizacao e salva ela nas pastas.\n",
    "    mapper.visualize(\n",
    "        graph,\n",
    "        title=title,\n",
    "        path_html=outPath,\n",
    "        custom_tooltips=Labels\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Ano da analise\n",
    "    analisedYear = '2011'\n",
    "    \n",
    "    # Tipo da analise\n",
    "    analisysType = 1 # domestico (1), internacional (2), ambos (3)\n",
    "\n",
    "    # Porcentagem de overlap\n",
    "    perc_overlap = 0.2\n",
    "\n",
    "    # Quantidade de hypercubos\n",
    "    n_cubes = 15\n",
    "\n",
    "\n",
    "    # Le e cria os dados\n",
    "    data = readAndCreateData()\n",
    "\n",
    "    # Cria a nuvem de pontos\n",
    "    pointCloud, Labels = createVectors(data, analisedYear, analisysType)\n",
    "    \n",
    "    # Normaliza a nuvem de pontos\n",
    "    normalizedPointCloud = normalize(pointCloud, norm='l2', axis=0)\n",
    "\n",
    "    # Aplica o algoritmo mapper e gera uma visualizacao\n",
    "    generateMapper(normalizedPointCloud, Labels, analisedYear, analisysType, perc_overlap, n_cubes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\franr\\\\Documents\\\\ic\\\\TDA-Dengue\\\\src\\\\data\\\\Cities-Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\franr\\Documents\\ic\\TDA-Dengue\\src\\socials.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=1'>2</a>\u001b[0m     main()\n",
      "\u001b[1;32mc:\\Users\\franr\\Documents\\ic\\TDA-Dengue\\src\\socials.ipynb Cell 9\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=11'>12</a>\u001b[0m n_cubes \u001b[39m=\u001b[39m \u001b[39m15\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=14'>15</a>\u001b[0m \u001b[39m# Le e cria os dados\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=15'>16</a>\u001b[0m data \u001b[39m=\u001b[39m readAndCreateData()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=17'>18</a>\u001b[0m \u001b[39m# Cria a nuvem de pontos\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=18'>19</a>\u001b[0m pointCloud, Labels \u001b[39m=\u001b[39m createVectors(data, analisedYear, analisysType)\n",
      "\u001b[1;32mc:\\Users\\franr\\Documents\\ic\\TDA-Dengue\\src\\socials.ipynb Cell 9\u001b[0m in \u001b[0;36mreadAndCreateData\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=1'>2</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=2'>3</a>\u001b[0m \u001b[39m    Realiza a leitura dos csv e organiza-os em um unico dict onde cada cidade possui seus dados\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=3'>4</a>\u001b[0m \u001b[39m    Exemplo do dict final:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=24'>25</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=25'>26</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=26'>27</a>\u001b[0m mergedData \u001b[39m=\u001b[39m OrderedDict()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=28'>29</a>\u001b[0m citiesData \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(citiesPath) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=29'>30</a>\u001b[0m socialData \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(socialPath)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franr/Documents/ic/TDA-Dengue/src/socials.ipynb#ch0000017?line=30'>31</a>\u001b[0m socialData\u001b[39m.\u001b[39mrename( columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mUnnamed: 0\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mCity\u001b[39m\u001b[39m'\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m )\n",
      "File \u001b[1;32mc:\\Users\\franr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\franr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\franr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\franr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\franr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m     f,\n\u001b[0;32m   1220\u001b[0m     mode,\n\u001b[0;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1227\u001b[0m )\n\u001b[0;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\franr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\franr\\\\Documents\\\\ic\\\\TDA-Dengue\\\\src\\\\data\\\\Cities-Data.csv'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c09827d00f9f395f539885cfa849c14ba4eadbf17dc271ab49956065b612b0e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
